{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3GX6t4h0LXJo6Zqrn+Y9m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeyanthan-gj/NLP-AND-LLM/blob/main/Named_Entity_Recognition_(NER)_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Named Entity Recognition (NER)\n",
        "**Named Entity Recognition (NER)** is a Natural Language Processing (NLP) task that identifies and classifies **named entities** in text into predefined categories such as people, organizations, locations, dates, and quantities.\n",
        "\n",
        "---\n",
        "\n",
        "## What does NER do?\n",
        "NER performs two main tasks:\n",
        "1. **Entity Detection** ‚Äì finds relevant entities in text  \n",
        "2. **Entity Classification** ‚Äì assigns a label to each entity\n",
        "\n",
        "### Example\n",
        "**Sentence:**  \n",
        "‚ÄúSundar Pichai is the CEO of Google and lives in California.‚Äù\n",
        "\n",
        "**Entities Identified:**\n",
        "\n",
        "| Entity        | Type |\n",
        "|--------------|------|\n",
        "| Sundar Pichai | PERSON |\n",
        "| Google        | ORGANIZATION |\n",
        "| California    | LOCATION |\n",
        "\n",
        "---\n",
        "## Approaches to NER\n",
        "\n",
        "### Rule-Based Approach\n",
        "- Uses manually defined linguistic rules  \n",
        "- Easy to understand but hard to scale  \n",
        "\n",
        "### Machine Learning Approach\n",
        "- Learns from labeled data  \n",
        "- Common models: HMM, CRF  \n",
        "\n",
        "### Deep Learning Approach\n",
        "- Automatically learns features from data  \n",
        "- Models: BiLSTM-CRF, Transformer-based models  \n"
      ],
      "metadata": {
        "id": "hjOrXen2Hmwr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rule-Based Named Entity Recognition (NER)\n",
        "Rule-based NER identifies entities using **manually defined patterns** such as regular expressions.  \n",
        "This approach does not require training data and works well for **simple, fixed patterns**.\n",
        "\n",
        "## Approach Used\n",
        "- Regular expressions (`re`)\n",
        "- Capitalization rules\n",
        "- Keyword-based matching\n",
        "\n"
      ],
      "metadata": {
        "id": "S7OtX_ijJ8uw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = \"Narendra Modi is the Prime Minister of India\"\n",
        "\n",
        "# Simple rule-based patterns\n",
        "person_pattern = r\"\\b[A-Z][a-z]+ [A-Z][a-z]+\\b\"\n",
        "location_pattern = r\"\\bCalifornia|India|USA\\b\"\n",
        "\n",
        "persons = re.findall(person_pattern, text)\n",
        "locations = re.findall(location_pattern, text)\n",
        "\n",
        "print(\"Persons:\", persons)\n",
        "print(\"Locations:\", locations)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqMRpMx2HzCC",
        "outputId": "5275ef49-9b36-405f-d7a6-ca2465dbb313"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Persons: ['Narendra Modi', 'Prime Minister']\n",
            "Locations: ['India']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advantages\n",
        "- Simple and fast\n",
        "- No external libraries or models needed\n",
        "\n",
        "## Limitations\n",
        "- Not scalable\n",
        "- Fails for complex or unseen patterns\n",
        "- Requires manual rule updates\n"
      ],
      "metadata": {
        "id": "PRzGttftKB_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning‚ÄìBased Named Entity Recognition (NLTK)\n",
        "This approach uses **classical NLP pipelines**:\n",
        "- Tokenization\n",
        "- Part-of-Speech (POS) tagging\n",
        "- Named Entity Chunking\n",
        "\n",
        "NLTK provides **pretrained statistical models** for these tasks.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YpWIADmUKeQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('maxent_ne_chunker_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSo0Y43UIxfZ",
        "outputId": "4fe036e5-fe3c-45cb-811b-698ef300a17f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "\n",
        "sentence = \"MS Dhoni was the captain of Indian Cricket Team\"\n",
        "\n",
        "tokens = word_tokenize(sentence)\n",
        "pos_tags = pos_tag(tokens)\n",
        "ner_tree = ne_chunk(pos_tags)\n",
        "\n",
        "print(ner_tree)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPa0KGpVI1cB",
        "outputId": "4aeddd5a-c707-4cf7-b154-25fcf7486f3c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  MS/NNP\n",
            "  (PERSON Dhoni/NNP)\n",
            "  was/VBD\n",
            "  the/DT\n",
            "  captain/NN\n",
            "  of/IN\n",
            "  (GPE Indian/JJ)\n",
            "  Cricket/NNP\n",
            "  Team/NN)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advantages\n",
        "- No manual rules needed\n",
        "- Better than pure rule-based systems\n",
        "\n",
        "## Limitations\n",
        "- Lower accuracy than deep learning models\n",
        "- Limited contextual understanding\n",
        "- Slower for large-scale applications"
      ],
      "metadata": {
        "id": "qeK2-7FSK53_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning‚ÄìBased Named Entity Recognition (spaCy)\n",
        "This approach uses **neural networks and word embeddings** to perform NER.\n",
        "spaCy models are trained on large annotated datasets and understand **context**.\n",
        "\n",
        "## Model Used\n",
        "- `en_core_web_sm`\n",
        "- Transformer-inspired architecture (lightweight version)\n",
        "\n",
        "## How It Works\n",
        "- Text is processed as a document object\n",
        "- The model predicts entity spans and labels\n",
        "- Each entity contains text and a semantic label\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "taBz2pkoLKHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_sm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb5GXtB2I-r5",
        "outputId": "7a8eb79a-7411-489e-9c31-f527c19a5db9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"Apple was founded by Steve Jobs in California in 1976\"\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, \"->\", ent.label_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JoCgaWVJBb5",
        "outputId": "f88d1fe6-a326-4198-9308-68f5fb918ba1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple -> ORG\n",
            "Steve Jobs -> PERSON\n",
            "California -> GPE\n",
            "1976 -> DATE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advantages\n",
        "- High accuracy\n",
        "- Context-aware\n",
        "- Industry-standard NLP library\n",
        "\n",
        "## Limitations\n",
        "- Requires more memory\n",
        "- Pretrained model may miss domain-specific entities"
      ],
      "metadata": {
        "id": "Psc2WZqPLSkW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üöÄ Exploring Named Entity Recognition (NER) in NLP\n",
        "\n",
        "Today, I worked on Named Entity Recognition (NER) ‚Äî a core task in Natural Language Processing (NLP) that helps identify and classify real-world entities such as people, organizations, locations, dates, and more from raw text.\n",
        "\n",
        "In this mini-project, I implemented and compared three different NER approaches, moving from basics to industry-standard solutions:\n",
        "\n",
        "üîπ 1. Rule-Based NER\n",
        "‚Ä¢ Uses regular expressions and linguistic rules\n",
        "‚Ä¢ Simple and fast\n",
        "‚Ä¢ Best for small, fixed patterns\n",
        "\n",
        "üîπ 2. Machine Learning‚ÄìBased NER (NLTK)\n",
        "‚Ä¢ Uses tokenization, POS tagging, and chunking\n",
        "‚Ä¢ Pretrained statistical models\n",
        "‚Ä¢ Better than rule-based, but limited context understanding\n",
        "\n",
        "üîπ 3. Deep Learning‚ÄìBased NER (spaCy)\n",
        "‚Ä¢ Uses neural networks and word embeddings\n",
        "‚Ä¢ Context-aware entity detection\n",
        "‚Ä¢ Widely used in real-world NLP applications\n",
        "\n",
        "üéØ This progression clearly shows how NER evolves from manual rules to powerful deep learning models.\n",
        "\n",
        "üìπ I‚Äôve shared a short demo video explaining the workflow and outputs step by step.\n",
        "\n",
        "üîó Code link:\n",
        "üëâ [Paste your GitHub / Colab link here]\n",
        "\n",
        "#NLP\n",
        "#NamedEntityRecognition\n",
        "#MachineLearning\n",
        "#DeepLearning\n",
        "#spaCy\n",
        "#NLTK\n",
        "#Python\n",
        "#AI\n",
        "#LearningJourney"
      ],
      "metadata": {
        "id": "rZXWZO36Ls9-"
      }
    }
  ]
}